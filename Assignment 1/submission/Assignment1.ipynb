{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oeRveD6E8T1q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import cvxpy as cp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQfG_NA28T1u"
      },
      "source": [
        "## Generate the random Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkZGkChD8T1x",
        "outputId": "2913f063-f46a-4887-c8bc-fa4946e547d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1 -1  1  1  1 -1 -1 -1 -1  1  1  1 -1 -1 -1  1 -1 -1 -1  1  1  1 -1 -1\n",
            " -1  1  1  1  1 -1  1  1 -1 -1  1  1 -1  1  1  1 -1  1 -1  1  1 -1 -1 -1\n",
            " -1  1 -1 -1  1 -1  1  1 -1 -1 -1 -1  1 -1 -1  1 -1 -1  1  1 -1  1  1  1\n",
            "  1 -1 -1  1 -1  1  1  1  1  1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1  1  1\n",
            "  1  1 -1 -1]\n",
            "[[8.92311919e-01 5.17576028e-01 8.17059209e-01 2.59403210e-01\n",
            "  9.25906087e-03 9.71903096e-02 7.97539063e-01 6.27777163e-01\n",
            "  5.03892928e-01 7.74041526e-01]\n",
            " [7.76606002e-01 4.67377071e-01 2.08834827e-01 4.76257918e-01\n",
            "  7.92382917e-01 6.90983139e-02 6.43466097e-01 5.59696720e-01\n",
            "  2.71485295e-01 6.08884657e-01]\n",
            " [6.56768378e-01 4.64746214e-01 4.09685353e-01 7.06114705e-01\n",
            "  9.66180171e-01 6.78357351e-01 5.99979791e-01 1.32238665e-01\n",
            "  7.13726891e-01 3.18150821e-01]\n",
            " [1.08828095e-01 4.63689527e-01 7.95430476e-01 5.14808203e-01\n",
            "  9.26239681e-01 8.82416651e-01 9.13825548e-01 3.09526389e-01\n",
            "  5.52754286e-01 2.21337169e-02]\n",
            " [5.46135647e-01 8.50308810e-01 3.15503894e-01 5.78384759e-01\n",
            "  5.18267190e-01 2.32341959e-01 6.02463632e-01 1.34796494e-01\n",
            "  3.24921560e-01 6.87879127e-01]\n",
            " [3.08199545e-01 2.51855752e-01 9.47591873e-01 7.86582723e-01\n",
            "  5.86516040e-01 2.25835256e-01 7.15768834e-01 1.05016338e-01\n",
            "  7.33683613e-01 6.27145513e-01]\n",
            " [6.28270794e-01 6.25905628e-01 3.63221108e-01 4.01743563e-01\n",
            "  7.34591422e-01 8.22429557e-01 1.22361825e-01 8.21179877e-01\n",
            "  7.53588938e-01 2.74989636e-01]\n",
            " [2.87047541e-01 1.84823268e-01 4.70773513e-01 3.62311246e-01\n",
            "  3.26961392e-01 4.78326973e-01 2.48935994e-01 3.92161452e-01\n",
            "  4.39536783e-01 8.79629126e-01]\n",
            " [6.71794168e-01 2.95221749e-01 6.54694345e-01 3.35120380e-01\n",
            "  1.56354880e-01 4.24453513e-01 8.40110766e-01 9.41141448e-01\n",
            "  8.22028679e-01 7.33432657e-01]\n",
            " [6.12218737e-01 7.31844907e-01 1.25356040e-01 6.56107690e-01\n",
            "  2.48586506e-01 8.51163706e-01 8.12066750e-01 9.79836893e-02\n",
            "  3.89883205e-01 4.55264667e-01]\n",
            " [1.21863510e-01 3.51485708e-01 6.51122096e-01 5.62102979e-01\n",
            "  1.45596321e-01 7.95882586e-01 2.11291104e-01 1.54455600e-01\n",
            "  3.13146789e-01 5.45110435e-01]\n",
            " [5.39889697e-01 3.36907081e-01 3.00021752e-01 9.07824340e-01\n",
            "  7.83619713e-01 3.15694181e-02 2.72183654e-01 3.67121224e-01\n",
            "  5.36017282e-01 6.88547630e-01]\n",
            " [7.59730737e-01 2.99727831e-01 5.48730526e-01 1.46375689e-01\n",
            "  9.68034717e-02 3.78988379e-01 3.43455329e-01 8.48939983e-01\n",
            "  8.95766399e-01 1.25143722e-01]\n",
            " [2.47744628e-01 4.14501655e-01 6.28337884e-01 8.12516688e-01\n",
            "  9.86524190e-01 2.23575018e-01 8.03865804e-01 7.68174351e-01\n",
            "  8.11145668e-01 7.52541089e-01]\n",
            " [1.96036552e-01 3.40259341e-01 7.91478258e-01 1.88293171e-01\n",
            "  2.32766299e-01 6.01753159e-01 7.39871990e-01 4.38325298e-01\n",
            "  4.14677893e-01 6.15474077e-01]\n",
            " [1.53528237e-02 7.03870132e-01 3.64074284e-01 4.58474048e-01\n",
            "  3.85506222e-01 4.51501671e-01 5.98993898e-01 2.07691220e-01\n",
            "  3.90723075e-01 2.95917007e-01]\n",
            " [3.37565451e-01 4.01235656e-01 5.74320644e-01 4.60478325e-01\n",
            "  7.23611589e-01 1.28318779e-01 8.17669419e-01 6.00531525e-04\n",
            "  6.42299245e-01 3.25169805e-01]\n",
            " [5.87929694e-02 2.35414057e-01 5.49442774e-01 5.77957205e-01\n",
            "  5.59265461e-01 9.65437699e-01 8.93461361e-01 6.85663911e-01\n",
            "  7.33888730e-01 4.01642618e-01]\n",
            " [8.12121526e-01 5.59482584e-01 7.87011571e-01 8.24701812e-01\n",
            "  4.80280696e-01 7.41874447e-01 9.32340486e-01 5.18078313e-01\n",
            "  6.00754383e-01 7.69511337e-02]\n",
            " [6.18519978e-01 5.05014615e-01 3.74843053e-01 4.75290838e-02\n",
            "  3.81887363e-01 6.44819723e-01 1.82812510e-01 7.31114482e-01\n",
            "  3.10176649e-01 7.58644166e-01]\n",
            " [8.25914787e-01 6.79422118e-01 8.67367852e-02 2.56604426e-01\n",
            "  2.07273249e-01 2.55246834e-01 1.31068488e-01 5.29395048e-01\n",
            "  1.47806465e-01 9.59880760e-01]\n",
            " [8.12664895e-01 4.79446981e-01 1.73787086e-01 9.37242482e-01\n",
            "  3.09256236e-01 8.53001337e-01 9.13362064e-01 8.66990410e-01\n",
            "  9.04268960e-01 5.37530317e-01]\n",
            " [2.41157138e-01 1.87263044e-01 7.72831182e-01 4.10060995e-02\n",
            "  7.76974208e-01 3.76247089e-01 9.72730303e-01 5.44622746e-01\n",
            "  1.18188323e-04 8.08971527e-01]\n",
            " [3.70947892e-01 4.36908683e-01 5.10332548e-01 8.58441968e-01\n",
            "  3.93430739e-01 8.93421731e-01 1.37283951e-01 6.34303566e-01\n",
            "  7.91947324e-01 4.67021254e-02]\n",
            " [8.45661725e-01 5.06093727e-01 9.28432767e-01 6.88142790e-02\n",
            "  3.42023375e-01 3.74190917e-01 2.09856865e-01 5.42249086e-01\n",
            "  6.08529592e-01 9.74391692e-01]\n",
            " [5.05944101e-01 4.37399812e-01 4.98365828e-01 6.91752531e-01\n",
            "  2.43789875e-02 1.00790853e-01 6.61752595e-01 1.49331606e-01\n",
            "  2.88661702e-01 3.66153183e-02]\n",
            " [9.93494177e-01 6.01216326e-01 4.79123317e-02 6.67283523e-01\n",
            "  2.96732223e-01 3.57911245e-01 2.70052565e-01 6.39064558e-01\n",
            "  2.79052427e-02 6.89943845e-01]\n",
            " [4.51141761e-01 4.21479262e-01 9.56328556e-01 5.08074544e-01\n",
            "  4.11079775e-02 4.23870683e-01 1.37104185e-01 8.63176832e-01\n",
            "  9.87793768e-02 2.13087530e-01]\n",
            " [5.67127909e-01 7.25400793e-01 6.58462966e-01 2.78884862e-02\n",
            "  4.50454283e-01 5.18276435e-01 7.07360501e-01 7.31062780e-01\n",
            "  8.93685750e-01 7.23139265e-01]\n",
            " [2.87066446e-01 8.23313334e-02 6.24740658e-01 2.67813881e-01\n",
            "  5.23166714e-01 5.94710771e-01 2.68770468e-01 7.49858742e-01\n",
            "  4.26227035e-01 2.88793969e-01]\n",
            " [6.11910462e-01 7.48991185e-01 3.54707185e-01 3.86765378e-01\n",
            "  2.74314519e-01 5.25562999e-01 2.44333019e-01 2.16190309e-01\n",
            "  5.78690960e-01 6.23634893e-01]\n",
            " [7.38017716e-01 9.66643870e-01 4.70689953e-01 4.82144603e-01\n",
            "  1.54554665e-01 9.57048214e-01 1.88410354e-01 4.74411033e-02\n",
            "  6.69396285e-01 5.05441187e-01]\n",
            " [7.61286292e-02 6.86189825e-01 1.20086295e-02 4.35882292e-01\n",
            "  6.33031926e-01 5.63251108e-01 6.75742114e-02 4.03049744e-01\n",
            "  4.02685180e-01 4.07534957e-01]\n",
            " [6.25351726e-01 3.70528722e-01 3.70225012e-01 3.06279496e-01\n",
            "  7.65242983e-01 4.89387355e-01 6.25839866e-01 1.38876239e-01\n",
            "  5.13338224e-01 2.49907685e-01]\n",
            " [5.23435446e-01 8.53060918e-01 6.92751795e-01 7.84186283e-02\n",
            "  8.99356823e-01 3.13898414e-01 9.17371758e-01 7.71598051e-01\n",
            "  5.74711722e-01 1.56920193e-01]\n",
            " [8.02673451e-01 6.60584588e-01 2.67424353e-01 4.63919700e-01\n",
            "  5.23544169e-02 8.96698127e-01 4.04072590e-01 6.68533662e-01\n",
            "  2.47728565e-01 9.21681604e-01]\n",
            " [8.30140292e-01 2.78078125e-01 7.76729509e-01 3.39489717e-01\n",
            "  7.47529153e-01 6.22323637e-01 7.53231693e-01 4.39863560e-01\n",
            "  8.18537250e-01 6.18689921e-01]\n",
            " [1.04458347e-01 6.95119500e-01 4.02488379e-01 8.88424927e-01\n",
            "  6.91114130e-01 8.98788298e-01 9.70780275e-01 8.32061784e-01\n",
            "  7.57099774e-01 9.85928368e-01]\n",
            " [4.00297133e-01 3.32736722e-01 9.35494967e-01 7.07403288e-01\n",
            "  5.64635937e-01 6.15625273e-01 2.62718167e-01 6.02974362e-01\n",
            "  9.73449083e-01 9.39313568e-01]\n",
            " [8.33315240e-01 4.79318082e-01 9.43196430e-01 4.12377529e-01\n",
            "  6.90126155e-01 5.93576155e-01 4.55182971e-01 3.60887715e-01\n",
            "  2.50078904e-01 3.26562283e-01]\n",
            " [8.38190022e-01 3.76568285e-01 6.46849922e-01 6.90012379e-01\n",
            "  4.61476692e-01 4.02227762e-01 2.15342244e-01 2.94878137e-01\n",
            "  5.25496383e-01 7.47531633e-02]\n",
            " [4.43934373e-01 5.19214239e-01 2.95096191e-01 1.66854151e-01\n",
            "  2.04520591e-01 4.81155668e-01 7.56406298e-01 6.71534673e-01\n",
            "  6.44624780e-01 8.09878454e-01]\n",
            " [6.44223625e-01 9.16250072e-01 8.79399340e-01 8.09868049e-01\n",
            "  8.27613553e-01 3.41464222e-01 8.64358900e-01 5.18058576e-01\n",
            "  8.61803617e-01 5.85435984e-01]\n",
            " [8.10416968e-01 2.39479847e-01 8.60053360e-02 9.47057720e-01\n",
            "  5.74308003e-02 7.35482728e-01 9.12681822e-02 7.97078682e-01\n",
            "  3.60702164e-01 5.67275651e-01]\n",
            " [5.06461272e-01 2.81409608e-01 2.39615694e-02 3.31423528e-02\n",
            "  2.45208651e-01 2.86003370e-01 6.11986443e-01 8.91944663e-01\n",
            "  1.00450040e-01 4.48765004e-01]\n",
            " [8.13242920e-01 9.36365585e-02 7.82652700e-01 8.33786593e-01\n",
            "  2.50709871e-01 9.81441023e-01 8.15459134e-01 9.59362287e-02\n",
            "  5.69412551e-01 8.00517510e-01]\n",
            " [2.37623785e-01 1.86385856e-02 4.92761919e-01 3.12628068e-01\n",
            "  6.01274513e-01 5.56565665e-01 5.17681855e-01 1.04861022e-01\n",
            "  8.18889577e-01 2.13264240e-01]\n",
            " [6.65979575e-01 5.14115574e-01 7.54994991e-01 6.48205988e-01\n",
            "  5.50213627e-01 4.64196377e-01 5.62641971e-02 3.16600005e-01\n",
            "  7.70922306e-01 5.52953578e-01]\n",
            " [9.17971660e-01 1.21068391e-01 7.47321885e-01 2.70523420e-02\n",
            "  4.55808082e-01 9.59227570e-01 2.08608267e-01 4.26636839e-01\n",
            "  4.79081370e-01 1.07390306e-01]\n",
            " [6.79365278e-01 6.54067824e-01 7.35018923e-01 9.36066836e-01\n",
            "  1.92975736e-01 9.39046633e-01 1.06783440e-01 5.06748818e-02\n",
            "  5.61762574e-01 5.61596974e-01]\n",
            " [5.71176988e-01 2.86259768e-01 1.76618658e-02 6.94252158e-01\n",
            "  5.51373139e-02 8.38734682e-01 9.28490734e-01 1.39717020e-01\n",
            "  4.79456771e-01 9.43526047e-01]\n",
            " [9.51238917e-01 8.48572680e-02 1.71954345e-01 7.75555357e-02\n",
            "  7.82946679e-01 3.92550718e-01 7.70309681e-01 2.26247863e-01\n",
            "  6.77835806e-01 5.96328813e-01]\n",
            " [5.33760550e-01 6.99582106e-01 3.86596305e-01 2.71198637e-01\n",
            "  3.44189041e-01 7.33392538e-01 5.52320030e-01 2.71822586e-01\n",
            "  4.98270048e-01 2.23495101e-01]\n",
            " [8.74711225e-02 9.94002630e-01 4.94118316e-02 3.30413260e-01\n",
            "  5.92297439e-01 7.96382874e-01 1.92179200e-01 8.28475033e-01\n",
            "  5.75968937e-01 6.33708798e-01]\n",
            " [8.48785613e-01 3.73554614e-01 7.33469871e-01 7.18749924e-01\n",
            "  3.68049232e-01 8.56744977e-01 3.44840060e-01 4.42359676e-01\n",
            "  5.14254407e-01 4.73145312e-01]\n",
            " [2.64879396e-01 2.63834737e-01 9.86994812e-01 4.90164071e-01\n",
            "  1.27377770e-01 4.74735420e-01 8.84996352e-01 8.36763436e-01\n",
            "  8.28576747e-01 4.82881812e-01]\n",
            " [3.33600099e-02 9.52239692e-01 2.27066538e-01 3.76459251e-01\n",
            "  4.69110092e-01 7.12835094e-01 2.99638710e-01 3.75432081e-01\n",
            "  8.04210184e-01 4.79734908e-01]\n",
            " [1.99587287e-01 9.67694767e-01 9.94292869e-02 9.36026639e-01\n",
            "  8.41854290e-01 2.07314891e-01 4.97245402e-01 8.81792408e-02\n",
            "  2.21851954e-01 6.52421751e-01]\n",
            " [2.35249204e-02 4.28103052e-01 7.84024528e-01 9.39366601e-01\n",
            "  5.36460147e-01 8.46962519e-01 7.45999462e-01 5.27173471e-01\n",
            "  4.60947150e-02 8.16278659e-01]\n",
            " [1.48543925e-01 4.79406842e-02 9.91539025e-02 6.62972365e-01\n",
            "  3.35464282e-01 1.51557360e-02 2.71952834e-01 3.49349004e-01\n",
            "  5.75601487e-01 8.77688358e-01]\n",
            " [4.41141352e-01 5.68999983e-01 5.46120277e-01 7.32530757e-01\n",
            "  7.38935989e-01 1.88279852e-01 5.79210541e-01 1.01641869e-02\n",
            "  8.37393882e-01 3.10439370e-01]\n",
            " [7.90030211e-01 5.82493908e-01 5.65293732e-01 6.46070722e-01\n",
            "  5.66245065e-01 7.51981937e-02 1.18991413e-01 8.99291250e-01\n",
            "  4.85579693e-01 7.84372392e-01]\n",
            " [6.89653781e-01 9.99167347e-01 4.86715796e-01 8.64837682e-01\n",
            "  3.80212709e-01 8.23362680e-01 3.56571547e-01 2.96399849e-01\n",
            "  1.96019160e-01 7.38030154e-01]\n",
            " [3.68397691e-01 4.50379894e-01 2.64988382e-01 8.75525947e-01\n",
            "  7.51740650e-01 8.72563653e-03 8.22245007e-01 3.17998256e-01\n",
            "  1.08735174e-02 1.37870672e-01]\n",
            " [4.33303589e-02 7.09916171e-01 4.57434450e-01 1.96718020e-01\n",
            "  2.51377133e-02 9.94173250e-01 7.99428255e-01 6.70902145e-01\n",
            "  9.12551550e-01 4.04411093e-01]\n",
            " [8.12069734e-01 4.98812081e-01 7.21948356e-01 3.40263035e-01\n",
            "  4.02955405e-01 3.55259516e-01 2.30213850e-01 4.06903095e-01\n",
            "  1.66413058e-01 5.17407563e-01]\n",
            " [2.09395973e-01 9.27210475e-01 8.37889575e-01 8.21625686e-01\n",
            "  1.57269267e-01 4.62914362e-01 4.88893493e-01 9.13481254e-01\n",
            "  8.68540738e-01 3.35556575e-01]\n",
            " [9.97267977e-01 5.76607339e-01 1.28794935e-01 5.67348351e-01\n",
            "  3.29950781e-01 7.62138000e-01 1.80103708e-01 7.37457467e-01\n",
            "  6.18477383e-02 5.83966021e-01]\n",
            " [3.67706285e-01 3.67266384e-02 2.93981614e-01 8.05443632e-02\n",
            "  5.46321651e-01 8.93272852e-01 2.10681013e-01 6.65082375e-01\n",
            "  8.89365414e-01 6.14827153e-01]\n",
            " [3.81065703e-01 1.71043412e-01 9.12493247e-01 6.17671867e-01\n",
            "  9.57942748e-01 5.12127548e-01 3.41647542e-01 7.01360313e-01\n",
            "  6.11147568e-01 4.22565188e-01]\n",
            " [3.74970502e-01 6.52207122e-01 4.09000468e-01 8.54248521e-01\n",
            "  5.27403294e-01 5.11442868e-01 9.87011069e-01 3.44376413e-02\n",
            "  8.14766348e-01 5.52169345e-01]\n",
            " [1.55216872e-01 9.18254466e-01 6.80755211e-01 7.11985819e-01\n",
            "  7.51440316e-01 2.48407021e-01 6.01793523e-01 8.38072808e-01\n",
            "  3.04434155e-01 4.18040523e-01]\n",
            " [5.77534281e-01 1.82317062e-01 1.92184253e-01 3.45480921e-01\n",
            "  4.11077822e-01 7.56836378e-01 4.52103985e-01 5.06841580e-01\n",
            "  6.67618649e-01 4.68565982e-01]\n",
            " [2.75919976e-01 5.69397812e-01 3.10610197e-01 8.90816517e-01\n",
            "  5.41923498e-01 5.13813815e-01 5.74083964e-01 1.53390339e-01\n",
            "  8.36897385e-01 8.14980587e-02]\n",
            " [1.27854984e-01 7.03529205e-01 5.66615319e-01 6.92286718e-01\n",
            "  6.34586482e-02 3.02825086e-01 8.27364551e-01 5.01233695e-01\n",
            "  9.13819572e-01 3.85739556e-01]\n",
            " [7.77489394e-02 8.58526834e-02 3.45904506e-01 8.48068980e-01\n",
            "  9.65734174e-02 8.66476741e-01 8.05482555e-01 4.67177708e-01\n",
            "  3.25504922e-01 5.93055404e-01]\n",
            " [7.94987538e-01 3.15271933e-02 4.97878884e-01 5.26002663e-02\n",
            "  3.57591213e-01 2.63073405e-01 4.63396121e-01 1.49922141e-01\n",
            "  1.38631535e-01 5.52038362e-01]\n",
            " [5.53183274e-01 2.51384113e-01 3.05087448e-01 1.83218616e-01\n",
            "  8.05746238e-02 7.55875212e-01 2.91972982e-01 7.26763644e-01\n",
            "  1.17764305e-01 8.90904731e-01]\n",
            " [5.16022719e-01 5.27849923e-01 1.11862527e-01 4.45328259e-01\n",
            "  5.57601852e-01 3.30827315e-01 1.69340664e-02 3.00677553e-01\n",
            "  7.20351635e-01 4.07513980e-02]\n",
            " [8.08651522e-01 3.26469125e-01 5.73208881e-01 7.82034595e-01\n",
            "  9.48282868e-01 6.64676064e-01 4.97572895e-01 3.12183013e-02\n",
            "  4.37474553e-02 9.21443025e-02]\n",
            " [1.44998653e-01 2.06876905e-01 9.89653975e-01 9.67659803e-01\n",
            "  4.16221092e-01 6.44836858e-01 5.88004612e-01 1.57421635e-01\n",
            "  3.02827959e-01 3.00846200e-01]\n",
            " [7.78731600e-01 6.99286835e-01 4.98504607e-01 4.81735129e-01\n",
            "  6.89238962e-01 2.25256878e-01 1.87772887e-01 9.19597669e-01\n",
            "  2.44444560e-01 7.05679459e-01]\n",
            " [5.32914550e-01 5.55460069e-01 8.45507943e-03 7.39987008e-01\n",
            "  3.59969202e-02 4.30731621e-01 5.58170583e-01 1.39607871e-01\n",
            "  7.07196051e-01 7.22121981e-01]\n",
            " [2.77637206e-02 9.69007442e-01 2.14542011e-01 5.58587124e-01\n",
            "  6.08805151e-01 1.63845634e-01 7.98038809e-01 9.08613588e-01\n",
            "  4.03678730e-01 6.35335840e-01]\n",
            " [5.34994528e-01 5.30817965e-01 4.06990771e-01 5.14930920e-01\n",
            "  4.00468142e-01 9.93717988e-01 5.08930087e-02 5.59014933e-01\n",
            "  7.08100119e-01 5.50895344e-01]\n",
            " [4.55439404e-01 4.04253294e-01 3.32236628e-01 8.87976717e-01\n",
            "  9.89203371e-01 1.06264029e-01 6.83072050e-02 3.19831082e-01\n",
            "  2.39113450e-02 6.50423306e-01]\n",
            " [3.68350217e-01 7.64527518e-01 8.97397165e-01 5.20815108e-01\n",
            "  3.45528726e-01 2.74835739e-01 6.43301978e-01 7.73471114e-01\n",
            "  9.55431844e-01 9.05380440e-01]\n",
            " [2.18238546e-01 8.52443268e-01 4.04337314e-01 7.39442857e-01\n",
            "  7.20099672e-01 9.75732478e-01 3.52761912e-01 1.39035082e-01\n",
            "  4.01503373e-01 9.18471848e-01]\n",
            " [7.60764528e-01 5.03975276e-01 3.37641524e-01 7.80011324e-01\n",
            "  7.98854178e-01 1.39823559e-01 6.04905054e-01 9.06333469e-01\n",
            "  5.23573603e-01 7.15954068e-02]\n",
            " [4.09097674e-02 1.88054998e-02 4.06117047e-01 7.92273468e-01\n",
            "  4.40400829e-01 4.16067964e-02 5.18298197e-01 2.95632785e-01\n",
            "  3.61645603e-01 4.32417726e-01]\n",
            " [3.24529455e-01 3.89459116e-01 8.35618055e-01 7.30926185e-01\n",
            "  4.06663067e-01 9.69438617e-01 9.25929875e-01 1.54443205e-01\n",
            "  2.33044257e-01 1.48450401e-01]\n",
            " [5.30002605e-01 8.63884728e-01 1.03635311e-01 3.05522333e-01\n",
            "  9.98537342e-01 2.12471166e-01 9.04127101e-01 3.79106452e-01\n",
            "  9.45161269e-01 5.65042686e-02]\n",
            " [9.48970856e-02 4.81229442e-02 7.55760655e-01 4.61798727e-01\n",
            "  6.28099128e-02 1.90609722e-01 9.05881140e-01 7.12000195e-01\n",
            "  1.98534890e-01 4.90367184e-01]\n",
            " [1.49673222e-01 7.24039699e-01 1.73789067e-01 8.81969716e-03\n",
            "  6.36512698e-01 4.33577201e-01 1.05120666e-02 7.30298640e-01\n",
            "  4.33777974e-01 2.53428641e-01]\n",
            " [6.10822930e-01 5.26478850e-01 7.56360775e-01 3.85152566e-01\n",
            "  6.49305421e-01 9.85965346e-01 2.70661408e-01 6.14151775e-01\n",
            "  4.30249612e-01 4.86348097e-01]\n",
            " [4.20526865e-01 4.32742768e-01 7.03972565e-01 6.91947416e-01\n",
            "  1.47107526e-01 1.70641148e-01 2.32076912e-01 6.19997887e-01\n",
            "  9.90764749e-01 2.11074721e-01]\n",
            " [6.12832182e-01 5.84048653e-01 1.65531276e-01 1.82158287e-01\n",
            "  6.21516534e-01 6.68258210e-01 6.33143351e-01 9.84247978e-01\n",
            "  8.23468595e-02 3.40807067e-01]\n",
            " [5.63853434e-01 6.67655183e-01 6.98787709e-02 1.11268641e-01\n",
            "  6.78581625e-01 4.66542229e-01 8.12334212e-01 9.04448930e-01\n",
            "  8.94839406e-02 1.12563622e-01]\n",
            " [3.43752896e-01 2.44866449e-01 9.79121191e-01 3.42353128e-01\n",
            "  6.86634156e-01 2.18806010e-01 9.62662545e-01 7.62280313e-02\n",
            "  3.83508447e-02 9.24228501e-01]\n",
            " [7.10902396e-01 4.56828737e-01 7.95481166e-01 6.23297927e-01\n",
            "  6.61219633e-01 9.34664485e-03 9.07376963e-01 7.40327516e-01\n",
            "  8.89860898e-01 3.82582377e-01]]\n"
          ]
        }
      ],
      "source": [
        "# We first generate a random dataset with number of features (m = 10) and number of instances (n = 100)\n",
        "# We also generate a random label vector y \\in {-1,1}\n",
        "\n",
        "n = 100 # Number of instances\n",
        "m = 10  # Number of Features \n",
        "\n",
        "X = np.random.rand(n,m) \n",
        "y = np.random.rand(n) # n-dimensional vector\n",
        "ybin = [(int(yi >= 0.5) - int(yi < 0.5)) for yi in y]\n",
        "y = np.array(ybin)\n",
        "w = np.random.rand(m, 1) # m-dimensional vector\n",
        "print(y)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZyGGnzw8T1y"
      },
      "source": [
        "## An Implementation of the Logistic Loss \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6CxYuAx-8T1z"
      },
      "outputs": [],
      "source": [
        "def LogisticLossNaive(w, X, y, lam):\n",
        "    # Computes the cost function for all the training samples\n",
        "    # where f is the function value and g is the gradient\n",
        "\n",
        "    n = w.shape[0] # feature length \n",
        "    m = X.shape[0] # number of training examples\n",
        "    \n",
        "    g = np.zeros((n,1))\n",
        "\n",
        "    l2_sum = 0\n",
        "    for i in range(n):\n",
        "      l2_sum += w[i][0]**2\n",
        "      g[i][0] += lam*w[i][0]\n",
        "\n",
        "    f = 0 # cost function \n",
        "    for i in range(m):\n",
        "      val =0 # storing the value of inner product of weight and row of X\n",
        "      for j in range(n):\n",
        "        val += w[j][0]*X[i][j]\n",
        "      f += np.log(1+np.exp(-y[i]*val))\n",
        "      for j in range(n):\n",
        "        g[j][0] += -y[i]*X[i][j]/(1+np.exp(val*y[i]))\n",
        "      \n",
        "    f += 0.5*lam*l2_sum\n",
        "    \n",
        "    return [f, g]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24xvCEq18T10",
        "outputId": "d0f6d405-36ba-4864-cb85-03bce1b0ab87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken = 0.019153356552124023\n",
            "Function value = 140.11780276559827\n",
            "Printing Gradient:\n",
            "[[20.65308792]\n",
            " [19.4908496 ]\n",
            " [23.3815784 ]\n",
            " [22.13233807]\n",
            " [23.25180053]\n",
            " [22.07824811]\n",
            " [25.46977585]\n",
            " [20.04218285]\n",
            " [25.08716677]\n",
            " [22.91347968]]\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "[f,g] = LogisticLossNaive(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value = \" + str(f))\n",
        "print(\"Printing Gradient:\")\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmv-y3XP8T11"
      },
      "source": [
        "## An Implementation of the Least Squares \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "E2nqhJfQ8T12"
      },
      "outputs": [],
      "source": [
        "def LeastSquaresNaive(w, X, y, lam):\n",
        "    # Computes the cost function for all the training samples\n",
        "    # where f is the function value and g is the gradient\n",
        "\n",
        "    n = w.shape[0] # feature length \n",
        "    m = X.shape[0] # number of training examples\n",
        "\n",
        "    y_hat = np.zeros(m)\n",
        "    g = np.zeros((n,1))\n",
        "    f =0\n",
        "\n",
        "    l2_sum = 0\n",
        "    for i in range(n):\n",
        "      l2_sum += w[i][0]**2\n",
        "      g[i][0] += lam*w[i][0]\n",
        "\n",
        "    for i in range(m):\n",
        "      for j in range(n):\n",
        "        y_hat[i] += X[i][j]*w[j][0]\n",
        "\n",
        "      for j in range(n):\n",
        "        g[j] += 2*(y_hat[i]-y[i])*X[i][j]\n",
        "      \n",
        "      f += (y_hat[i] - y[i])**2\n",
        "\n",
        "    f += 0.5*lam*l2_sum\n",
        "\n",
        "    return [f, g]     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xdgy_Ml8T13",
        "outputId": "9624ac79-f0a0-4e9a-90a1-ef76a3c1b363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken = 0.008816242218017578\n",
            "Function value = 765.5306437937076\n",
            "Printing Gradient:\n",
            "[[247.02390047]\n",
            " [240.72484553]\n",
            " [265.22377036]\n",
            " [267.2425564 ]\n",
            " [257.02299075]\n",
            " [262.49868215]\n",
            " [283.15028227]\n",
            " [238.79272922]\n",
            " [273.41676204]\n",
            " [258.88130636]]\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "[f,g] = LeastSquaresNaive(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value = \" + str(f))\n",
        "print(\"Printing Gradient:\")\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R27uE8hA8T14"
      },
      "source": [
        "## An Implementation of the Hinge Loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6BHEVrOS8T14"
      },
      "outputs": [],
      "source": [
        "def HingeLossNaive(w, X, y, lam):\n",
        "    # Computes the cost function for all the training samples\n",
        "    # where f is the function value and g is the gradient\n",
        "    n = w.shape[0] # feature length \n",
        "    m = X.shape[0] # number of training examples\n",
        "\n",
        "    g = np.zeros((n,1))\n",
        "    f= 0\n",
        "\n",
        "    l2_sum = 0\n",
        "    for i in range(n):\n",
        "      l2_sum += w[i][0]**2\n",
        "      g[i][0] += lam*w[i][0]\n",
        "\n",
        "    for i in range(m):\n",
        "      val =0 # storing the value of inner product of weight and row of X\n",
        "      for j in range(n):\n",
        "        val += w[j][0]*X[i][j]\n",
        "      f += max(0, 1-y[i]*val)\n",
        "      if 1-y[i]*val > 0:\n",
        "        for j in range(n):\n",
        "          g[j][0] += -y[i]*X[i][j]\n",
        "\n",
        "    f += 0.5*lam*l2_sum\n",
        "\n",
        "    return [f, g]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3UV-a5I8T15",
        "outputId": "a9af1c05-2b00-4a0f-dc03-03da3285db87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken = 0.007283926010131836\n",
            "Function value = 183.39961206390316\n",
            "Printing Gradient:\n",
            "[[24.36781137]\n",
            " [23.42740412]\n",
            " [27.00925743]\n",
            " [26.15522556]\n",
            " [26.79737846]\n",
            " [26.13755516]\n",
            " [29.23429996]\n",
            " [24.07483467]\n",
            " [29.13480161]\n",
            " [26.96471302]]\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "[f,g] = HingeLossNaive(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value = \" + str(f))\n",
        "print(\"Printing Gradient:\")\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fZTyeTo8T16"
      },
      "source": [
        "## Scalability of the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk-mbsbJ8T17",
        "outputId": "eb1e211c-707e-4c25-f7f7-cb89d041e5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-17b9c6c58985>:20: RuntimeWarning: overflow encountered in exp\n",
            "  f += np.log(1+np.exp(-y[i]*val))\n",
            "<ipython-input-5-17b9c6c58985>:22: RuntimeWarning: overflow encountered in exp\n",
            "  g[j][0] += -y[i]*X[i][j]/(1+np.exp(val*y[i]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Loss\n",
            "Time Taken = 8.705084323883057\n",
            "Function value = inf\n",
            "Printing Gradient:\n",
            "[[23.47291348]\n",
            " [18.30352544]\n",
            " [21.56395418]\n",
            " ...\n",
            " [20.70788864]\n",
            " [20.40633109]\n",
            " [21.35320558]]\n",
            "Least Square\n",
            "Time Taken = 4.2392542362213135\n",
            "Function value = 629204342.6278816\n",
            "Printing Gradient:\n",
            "[[256936.88452829]\n",
            " [202634.63426419]\n",
            " [249069.88869177]\n",
            " ...\n",
            " [225531.29065722]\n",
            " [247023.52015019]\n",
            " [244225.93992716]]\n",
            "Hinge Loss\n",
            "Time Taken = 3.4823145866394043\n",
            "Function value = 114642.60335262673\n",
            "Printing Gradient:\n",
            "[[23.47291348]\n",
            " [18.30352544]\n",
            " [21.56395418]\n",
            " ...\n",
            " [20.70788864]\n",
            " [20.40633109]\n",
            " [21.35320558]]\n"
          ]
        }
      ],
      "source": [
        "n = 100\n",
        "m = 10000\n",
        "\n",
        "X = np.random.rand(n,m)\n",
        "y = np.random.rand(n)\n",
        "ybin = [(int(yi >= 0.5) - int(yi < 0.5)) for yi in y]\n",
        "y = np.array(ybin)\n",
        "w = np.random.rand(m, 1)\n",
        "\n",
        "start = time.time()\n",
        "[f,g] = LogisticLossNaive(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Logistic Loss\")\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value = \" + str(f))\n",
        "print(\"Printing Gradient:\")\n",
        "print(g)\n",
        "\n",
        "start = time.time()\n",
        "[f,g] = LeastSquaresNaive(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Least Square\")\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value = \" + str(f))\n",
        "print(\"Printing Gradient:\")\n",
        "print(g)\n",
        "\n",
        "start = time.time()\n",
        "[f,g] = HingeLossNaive(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Hinge Loss\")\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value = \" + str(f))\n",
        "print(\"Printing Gradient:\")\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ysqu9aG8T18"
      },
      "source": [
        "## Implement a vectorized version "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "jFgiDzlY8T19"
      },
      "outputs": [],
      "source": [
        "def LogisticLossVec(w, X, y, lam):\n",
        "    # Computes the cost function for all the training samples\n",
        "    # where f is the function value and g is the gradient\n",
        "\n",
        "    pdt = np.dot(X,w).reshape(-1,1)\n",
        "    f =  0.5*lam*np.sum(w**2) + np.sum(np.log(1+np.exp(-np.multiply(np.reshape(y,(n,1)),pdt))))\n",
        "    c = -np.multiply(np.reshape(y,(n,1)), 1/(1+np.exp(np.multiply(np.reshape(y,(n,1)),pdt))))\n",
        "    g = lam*w+ np.reshape(np.sum(np.multiply(X, c), axis=0), (-1,1))\n",
        "    return [f, g]     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "eP7vfNs28T19"
      },
      "outputs": [],
      "source": [
        "def LeastSquaresVec(w, X, y, lam):\n",
        "    # Computes the cost function for all the training samples\n",
        "    # where f is the function value and g is the gradient\n",
        "\n",
        "    y_hat = np.dot(X, w)\n",
        "    print(y_hat.shape)\n",
        "    f = np.sum((y_hat - y)**2) + 0.5*lam*np.sum(w**2)\n",
        "    g = lam*w\n",
        "    g += np.reshape(2*np.dot((y_hat.reshape(-1)-y).reshape(1, -1), X), (-1,1))\n",
        "    return [f, g]     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5WDu8ckX8T1-"
      },
      "outputs": [],
      "source": [
        "def HingeLossVec(w, X, y, lam):\n",
        "    # Computes the cost function for all the training samples\n",
        "    # where f is the function value and g is the gradient\n",
        "\n",
        "    pdt = 1 - np.multiply(y.reshape(-1, 1), np.dot(X,w))\n",
        "    pdt_xy = -np.multiply(y.reshape(-1, 1), X)\n",
        "    cost = 0.5*lam*np.sum(np.power(w, 2)) + np.sum(np.maximum(0, pdt))\n",
        "    grad = lam*w + np.reshape(np.sum(np.multiply(pdt_xy, np.sign(np.maximum(0, pdt))), axis=0), (-1,1))\n",
        "    return [f, g]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTKwmqjt8T1_",
        "outputId": "0e1b6d50-0d1c-4955-9bf4-bf5cabd9e3b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Loss\n",
            "Time Taken = 0.004076480865478516\n",
            "Function value = inf\n",
            "Printing Gradient:\n",
            "[[23.47291348]\n",
            " [18.30352544]\n",
            " [21.56395418]\n",
            " ...\n",
            " [20.70788864]\n",
            " [20.40633109]\n",
            " [21.35320558]]\n",
            "(100, 1)\n",
            "Least Square\n",
            "Time Taken = 0.007275581359863281\n",
            "Function value = 62920251624.59748\n",
            "Printing Gradient:\n",
            "[[256936.88452829]\n",
            " [202634.63426419]\n",
            " [249069.88869177]\n",
            " ...\n",
            " [225531.29065722]\n",
            " [247023.52015019]\n",
            " [244225.93992716]]\n",
            "Hinge Loss\n",
            "Time Taken = 0.020933866500854492\n",
            "Function value = 62920251624.59748\n",
            "Printing Gradient:\n",
            "[[256936.88452829]\n",
            " [202634.63426419]\n",
            " [249069.88869177]\n",
            " ...\n",
            " [225531.29065722]\n",
            " [247023.52015019]\n",
            " [244225.93992716]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-691fecca57fa>:6: RuntimeWarning: overflow encountered in exp\n",
            "  f =  0.5*lam*np.sum(w**2) + np.sum(np.log(1+np.exp(-np.multiply(np.reshape(y,(n,1)),pdt))))\n",
            "<ipython-input-18-691fecca57fa>:7: RuntimeWarning: overflow encountered in exp\n",
            "  c = -np.multiply(np.reshape(y,(n,1)), 1/(1+np.exp(np.multiply(np.reshape(y,(n,1)),pdt))))\n"
          ]
        }
      ],
      "source": [
        "n = 100\n",
        "m = 10000\n",
        "\n",
        "# X = np.random.rand(n,m)\n",
        "# y = np.random.rand(n)\n",
        "# ybin = [(int(yi >= 0.5) - int(yi < 0.5)) for yi in y]\n",
        "# y = np.array(ybin)\n",
        "# w = np.random.rand(m, 1)\n",
        "\n",
        "start = time.time()\n",
        "[f,g] = LogisticLossVec(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Logistic Loss\")\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value = \" + str(f))\n",
        "print(\"Printing Gradient:\")\n",
        "print(g)\n",
        "\n",
        "start = time.time()\n",
        "[f,g] = LeastSquaresVec(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Least Square\")\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value = \" + str(f))\n",
        "print(\"Printing Gradient:\")\n",
        "print(g)\n",
        "\n",
        "start = time.time()\n",
        "[f,g] = HingeLossVec(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Hinge Loss\")\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value = \" + str(f))\n",
        "print(\"Printing Gradient:\")\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqb1aR_Z8T1_"
      },
      "source": [
        "## Lets us code the above Loss Fuctions in CVXPY!\n",
        "\n",
        "CVXPY is an open source Python-embedded modeling language for convex optimization problems. Link: https://www.cvxpy.org/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4PHnzJA8T2A"
      },
      "outputs": [],
      "source": [
        "def LogisticLossCVXPY(w, X, y, lam):\n",
        "    # Computes the cost function for all the training samples\n",
        "    # where f is the function value and g is the gradient\n",
        "   \n",
        "    \n",
        "\n",
        "    return [f, g]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heXq-krM8T2B"
      },
      "outputs": [],
      "source": [
        "def LeastSquaresCVXPY(w, X, y, lam):\n",
        "    # Computes the cost function for all the training samples\n",
        "    # where f is the function value and g is the gradient\n",
        "\n",
        "    x = cp.Variable(n)\n",
        "    f = cp.sum_squares(X @ w- y)\n",
        "    g = cp.sum(0.5*lam*w**2)\n",
        "    \n",
        "    \n",
        "    return [f, g]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtBmHiQt8T2B"
      },
      "outputs": [],
      "source": [
        "def HingeLossCVXPY(w, X, y, lam):\n",
        "    # Computes the cost function for all the training samples\n",
        "    # where f is the function value and g is the gradient\n",
        "    return [f, g]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXiXaDdM8T2C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "n = 100\n",
        "m = 10\n",
        "\n",
        "X = np.random.rand(n,m)\n",
        "y = np.random.rand(n)\n",
        "ybin = [(int(yi >= 0.5) - int(yi < 0.5)) for yi in y]\n",
        "y = np.array(ybin)\n",
        "w = np.random.rand(m, 1)\n",
        "\n",
        "start = time.time()\n",
        "[f1,g1] = LogisticLossCVXPY(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value Naive = \" + str(f1))\n",
        "print(\"Printing Gradient Naive:\")\n",
        "print(g1)\n",
        "\n",
        "start = time.time()\n",
        "[f2,g2] = LeastSquaresCVXPY(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value For = \" + str(f2))\n",
        "print(\"Printing Gradient For:\")\n",
        "print(g2)\n",
        "\n",
        "start = time.time()\n",
        "[f2,g2] = HingeLossCVXPY(w,X,y,1)\n",
        "end = time.time()\n",
        "print(\"Time Taken = \" + str(end - start))\n",
        "print(\"Function value For = \" + str(f2))\n",
        "print(\"Printing Gradient For:\")\n",
        "print(g2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_74Lrswc8T2D"
      },
      "source": [
        "## Compare the losses with Graph\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWPbZeGs8T2D"
      },
      "outputs": [],
      "source": [
        "def LogisticLossFun(w, X, y, lam):\n",
        "    return error_ll\n",
        "\n",
        "def LeastSquaresFun(w, X, y, lam):\n",
        "    return error_ls\n",
        "\n",
        "def HingeLossFun(w, X, y, lam):\n",
        "    return error_hl\n",
        "\n",
        "def plot_errors(error_ll, error_ls, error_hl, num):\n",
        "    plt.plot(num, error_ll, label=\"Logistic Loss\")\n",
        "    plt.plot(num, error_ls, label=\"Least Squares\")\n",
        "    plt.plot(num, error_hl, label=\"Hinge Loss\")\n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_PJ2nzI8T2E"
      },
      "outputs": [],
      "source": [
        "n = 100\n",
        "m = 10000\n",
        "\n",
        "X = np.random.rand(n,m)\n",
        "y = np.random.rand(n)\n",
        "ybin = [(int(yi >= 0.5) - int(yi < 0.5)) for yi in y]\n",
        "y = np.array(ybin)\n",
        "w = np.random.rand(m, 1)\n",
        "\n",
        "error_ll = LogisticLossFun(w,X,y,1)\n",
        "error_ls = LeastSquaresFun(w,X,y,1)\n",
        "error_hl = HingeLossFun(w,X,y,1)\n",
        "plot_errors(error_ll, error_ls, error_hl, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6JnxMoc8T2E"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}